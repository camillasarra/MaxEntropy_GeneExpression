{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e50675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tqdm import trange\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----- use only some classes or all the data\n",
    "folder=folder_bin= DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf1ab8",
   "metadata": {},
   "source": [
    "# Find the parameters (as in find_ising.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f988d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 500\n",
    "label='all'\n",
    "# label=1\n",
    "\n",
    "n_samples = 10\n",
    "n_thermalize = 50000\n",
    "adam_step = 1e-2\n",
    "n_step_thermalize = 50\n",
    "n_step_compute_f = 20\n",
    "n_step_decorrelate = 2\n",
    "n_steps = 10000\n",
    "adam_step=1e-4\n",
    "eps=1e-7\n",
    "\n",
    "errs = np.loadtxt(f'{folder}f_dataERR_{d}_{label}.dat')\n",
    "# errs = np.ones(len(f_data))*1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeac01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- LARGE SYSTEMS FROM HERE _______________________________________\n",
    "f_data = np.loadtxt(f'{folder}f_data_{d}_{label}.dat')\n",
    "q1 = np.log((1-f_data[:d]+eps)/(1+f_data[:d]+eps))/2*d\n",
    "q1 = np.hstack((q1, [0]*int(d*(d-1)/2)))\n",
    "if not os.path.isfile(f'{folder}q_{d}_{label}.dat'):\n",
    "    print('no q found, start from independent')\n",
    "#     q = np.zeros(len(f_data))\n",
    "    q1 = np.log((1-f_data[:d]+eps)/(1+f_data[:d]+eps))/2*d\n",
    "    q = np.hstack((q1, [0]*int(d*(d-1)/2)))\n",
    "    q= tf.Variable(q, dtype=tf.float64)\n",
    "    \n",
    "else:\n",
    "    print('q loaded from file')\n",
    "    q = np.loadtxt(f'{folder}q_{d}_{label}.dat')\n",
    "#     q = np.zeros(len(f_data))\n",
    "#     q1 = np.log((1-f_data[:d])/(1+f_data[:d]))/2*d\n",
    "#     q = np.hstack((q1, [0]*int(d*(d-1)/2)))\n",
    "\n",
    "q= tf.Variable(q, dtype=tf.float64)\n",
    "h,J = get_hJ(q,d)\n",
    "h = tf.convert_to_tensor(h,dtype=tf.float64)\n",
    "J= tf.convert_to_tensor(J,dtype=tf.float64)\n",
    "if d==500: n_samples = 8000\n",
    "else: n_samples = 20000\n",
    "x = np.random.choice([-1,1], (n_samples,d))\n",
    "x = tf.convert_to_tensor(x,dtype=tf.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9908711",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, J1 = get_hJ(q1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zsum = np.loadtxt(f'{folder}_histosum_{d}_{label}.dat')\n",
    "# zsums = np.loadtxt(f'{folder}_histosums_{d}_{label}.dat')\n",
    "pzsum,zsum = np.loadtxt(f'{folder}histosum_{d}_{label}.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c26c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_thermalize = 200000\n",
    "x, energy_history = thermalize(x,J,h, NumSteps=n_thermalize , crange =trange)\n",
    "plt.plot(energy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbe5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, f_model = compute_f(x,J,h,StepsTherm=200,NumSteps=300, crange=lambda NumSteps, dtype: trange(NumSteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161ed97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_data = tf.convert_to_tensor(f_data, tf.float64)\n",
    "\n",
    "plt.scatter(f_data[:d].numpy(),f_model[:d].numpy(),s=5)\n",
    "plt.scatter(f_data[d:].numpy(),f_model[d:].numpy(),s=5)\n",
    "plt.scatter(f_data[sorted_different_indeces[0]].numpy(),f_model[sorted_different_indeces[0]].numpy(),s=10)\n",
    "plt.scatter(f_data[sorted_different_indeces[1]].numpy(),f_model[sorted_different_indeces[1]].numpy(),s=10)\n",
    "\n",
    "xmin, xmax = plt.gca().get_xlim()\n",
    "xx = np.linspace(xmin,xmax,100)\n",
    "plt.plot(xx,xx, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(errs, abs(f_data.numpy()-f_model.numpy()), s=0.1)\n",
    "xmin,xmax=plt.gca().get_xlim()\n",
    "xx=np.linspace(xmin,xmax,100)\n",
    "plt.plot(xx,xx, color='red')\n",
    "plt.plot(xx,xx*3, color='red')\n",
    "plt.plot(xx,xx*5, color='red', ls='--')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(abs(f_data.numpy()-f_model.numpy()))\n",
    "plt.plot(errs)\n",
    "plt.plot(errs*3)\n",
    "\n",
    "plt.title((abs(f_data.numpy()-f_model.numpy()) > 3*errs).sum())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50d0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{folder}f_model_{d}_{label}.dat',f_model.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- plot sum\n",
    "s=[]\n",
    "for _ in trange(100):\n",
    "    x, energy_history = thermalize(x,J,h, NumSteps=50 , crange =range)\n",
    "    s.append(x.numpy().sum(1))\n",
    "s=np.array(s).flatten()\n",
    "h0,h1 = np.unique(s, return_counts=True); h1=h1/h1.sum()\n",
    "plt.plot(h0,h1, '-', label='model', color='red')\n",
    "plt.plot(zsum,pzsum, '-', label='data', color='black')\n",
    "plt.xlabel('sum')\n",
    "plt.ylabel('P(sum)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcca248",
   "metadata": {},
   "source": [
    "## EVOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ceedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model_history =[]\n",
    "q_history=[]\n",
    "mre_history=[]\n",
    "m2conn_diff =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = tf.convert_to_tensor(f_data, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_different_indeces = np.argsort(abs((np.array(f_data - f_model)))/errs)[::-1]\n",
    "sorted_different_indeces = np.argsort(abs((np.array(f_data - f_model))))[::-1]\n",
    "\n",
    "i = sorted_different_indeces[:10]\n",
    "# print(i,(abs((np.array(f_data - f_model)))/errs)[i])\n",
    "# print(i,(abs((np.array(f_data - f_model))))[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=[100]\n",
    "d, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f03740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (abs((np.array(f_data - f_model)))/errs).argmax()\n",
    "np.savetxt(f'{folder}q_{d}_{label}.dat', np.array(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5027ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------- THERMALIZE\n",
    "adam_step = 1e-4\n",
    "optimizer = tf.optimizers.Adam(adam_step)\n",
    "\n",
    "n_steps =500\n",
    "n_step_thermalize = 200\n",
    "n_step_compute_f = 200\n",
    "n_step_decorrelate = 200\n",
    "\n",
    "for t in trange(n_steps):\n",
    "    h,J = get_hJ(q,d)\n",
    "    h = tf.convert_to_tensor(h,dtype=tf.float64)\n",
    "    J= tf.convert_to_tensor(J,dtype=tf.float64)\n",
    "    x,f_model = step(q,x,J,h,f_data, n_step_thermalize, n_step_compute_f,n_step_decorrelate, optimizer)\n",
    "    \n",
    "    f_model_history.append(f_model.numpy()[i])\n",
    "    q_history.append(q.numpy()[i]) \n",
    "       \n",
    "    mre_history.append(tf.reduce_mean((f_model-f_data)**2).numpy())\n",
    "    np.savetxt(f'{folder}q_{d}_{label}.dat', np.array(q))\n",
    "    \n",
    "    ## -------------------------- PLOTS -----------------------\n",
    "    ## --------------------------------------------------------\n",
    "    if ((t)%int(n_steps/20)==0):\n",
    "        x, energy_history = thermalize(x,J,h, NumSteps=1000 , crange =range)\n",
    "        #__________________________________________________________________________________\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.subplot(2,3,1)\n",
    "        plt.plot(mre_history[:])\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel(r'||$f_{data} - f_{model}||^2$')\n",
    "        # \n",
    "        # ---------------- Plot parameters evolution ------------------\n",
    "        \n",
    "        plt.subplot(2,3,2)\n",
    "        for isel in range(5):\n",
    "            plt.plot((np.array(f_model_history)[:,isel] - np.array(f_data)[i[isel]])/errs[i[isel]])\n",
    "            plt.axhline(0)\n",
    "            plt.axhline(3)\n",
    "            plt.axhline(-3)\n",
    "            plt.title(f'Abs diff {(np.array(f_model_history)[-1,isel] - np.array(f_data)[i[isel]]):.2f}')\n",
    "            \n",
    "            \n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel(r'$f_{model}/f_{data}$')\n",
    "        # ---------\n",
    "        plt.subplot(2,3,3)\n",
    "        plt.plot(np.array(q_history)[:,:2]/np.array(q_history)[0,:2])\n",
    "#         plt.plot(np.array(q_history)[:,])\n",
    "        \n",
    "        plt.title(f'Parameters {i[0]}')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('q')\n",
    "        plt.tight_layout()\n",
    "          \n",
    "        # ---------\n",
    "        plt.subplot(2,3,4)\n",
    "        plt.plot(abs(f_data.numpy()-f_model.numpy())/errs)\n",
    "#         plt.plot(errs)\n",
    "#         plt.plot(errs*3)        \n",
    "        plt.axhline(1)\n",
    "        plt.axhline(3)\n",
    "        plt.title(f'{(abs(f_data.numpy()-f_model.numpy())/errs).max():.4f}')\n",
    "\n",
    "        plt.subplot(2,3,5)\n",
    "        m2conn_data = np.array(f_data[d:] - np.array(f_data[:d][:,None]*f_data[:d][None,:])[np.triu_indices(d,1)])\n",
    "        m2conn_model = np.array(f_model[d:]-np.array(f_model[:d][:,None]*f_model[:d][None,:])[np.triu_indices(d,1)])\n",
    "        plt.scatter(m2conn_data[::10] ,m2conn_model[::10], s=5)\n",
    "        xmin, xmax = plt.gca().get_xlim()\n",
    "        xx = np.linspace(xmin,xmax,100)\n",
    "        plt.plot(xx,xx, color='red')\n",
    "        plt.title(r'$\\langle x_i x_j\\rangle_{conn}$')\n",
    "        \n",
    "        plt.subplot(2,3,6)\n",
    "        s=[]\n",
    "        for _ in range(10):\n",
    "            x, energy_history = thermalize(x,J,h, NumSteps=20 , crange =range)\n",
    "            s.append(x.numpy().sum(1))\n",
    "        s=np.array(s).flatten()\n",
    "        h0,h1 = np.unique(s, return_counts=True); h1=h1/h1.sum()\n",
    "        plt.plot(h0,h1, '-', label='model', color='red')\n",
    "        plt.plot(zsum,pzsum, '-', label='data', color='black')\n",
    "        plt.xlabel('sum')\n",
    "        plt.ylabel('P(sum)')\n",
    "        plt.ylim(0,0.015)\n",
    "  \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{folder}evolution_{d}_{label}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "    if ((abs(f_data.numpy()-f_model.numpy())<3*errs).sum()==0): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1505c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_saved=np.copy(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cef84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(i)):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(np.array(q_history)[:,ii])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(np.array(f_model_history)[:,ii])\n",
    "    plt.axhline(np.array(f_data)[i[ii]])\n",
    "    plt.axhline(np.array(f_data)[i[ii]] + 3*errs[i[ii]])\n",
    "    plt.axhline(np.array(f_data)[i[ii]] -3*errs[i[ii]])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmh = np.copy(f_model_history)\n",
    "# plt.plot(np.array(fmh))\n",
    "# plt.plot(np.array(f_model_history))\n",
    "\n",
    "# plt.axhline(np.array(f_data)[i])\n",
    "# plt.axhline(3*errs[i]+np.array(f_data)[i])\n",
    "# plt.axhline(-3*errs[i]+np.array(f_data)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b471936",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_thermalize = 50000\n",
    "x, energy_history = thermalize(x,J,h, NumSteps=n_thermalize , crange =trange)\n",
    "plt.plot(energy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, f_model = compute_f(x,J,h,StepsTherm=200,NumSteps=300, crange=lambda NumSteps, dtype: trange(NumSteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14feb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(errs, abs(f_data.numpy()-f_model.numpy()))\n",
    "xmin,xmax=plt.gca().get_xlim()\n",
    "xx=np.linspace(xmin,xmax,100)\n",
    "plt.plot(xx,xx, color='red')\n",
    "plt.plot(xx,xx*3, color='red')\n",
    "plt.plot(xx,xx*5, color='red')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(abs(f_data.numpy()-f_model.numpy()))\n",
    "plt.plot(errs)\n",
    "plt.plot(errs*3)\n",
    "# plt.title((abs(f_data.numpy()-f_model.numpy()) > 3*errs).sum())\n",
    "plt.title(f'{(abs(f_data.numpy()-f_model.numpy())/errs).max():.2f}')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a06e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- paramters\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(f_data.numpy()[:d], q.numpy()[:d]/d, s=1)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "m2conn_data = np.array(f_data[d:] - np.array(f_data[:d][:,None]*f_data[:d][None,:])[np.triu_indices(d,1)])\n",
    "# m2conn_model = np.array(f_model[d:]-np.array(f_model[:d][:,None]*f_model[:d][None,:])[np.triu_indices(d,1)])\n",
    "plt.scatter(m2conn_data, q.numpy()[d:]/d, s=0.05, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{folder}q_copy_{d}_{label}.dat', np.array(q))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c1b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = np.loadtxt(f'{folder}q_copy_{d}_{label}.dat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7af1f7",
   "metadata": {},
   "source": [
    "## moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = 8000\n",
    "# x = np.random.choice([-1,1], (n_samples,d))\n",
    "# x = tf.convert_to_tensor(x,dtype=tf.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22056080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_thermalize = 20000\n",
    "# x, energy_history = thermalize(x,J,h, NumSteps=n_thermalize , crange =trange)\n",
    "# plt.plot(energy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = np.loadtxt(f'{folder}_m2_{d}_{label}.dat')[:,0]\n",
    "m3 = np.loadtxt(f'{folder}_m3_{d}_{label}.dat')[:,0]\n",
    "m4 = np.loadtxt(f'{folder}_m4_{d}_{label}.dat')[:,0]\n",
    "indices = np.loadtxt(f'{folder}_m4_{d}_{label}.dat')[:,1:].astype(int)\n",
    "\n",
    "m2_model=np.zeros(len(m2))\n",
    "m3_model=np.zeros(len(m2))\n",
    "m4_model=np.zeros(len(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntries=500\n",
    "for _ in trange(ntries):\n",
    "    x, energy_history = thermalize(x,J,h, NumSteps=1000 , crange =range)\n",
    "    dx = x.numpy()-x.numpy().mean(0)\n",
    "    for ii in range(len(indices)):\n",
    "        i,j,k,l = indices[ii]   \n",
    "        m2_model[ii]+= (dx[:, [i,j]].prod(1).mean())\n",
    "        m3_model[ii]+= (dx[:, [i,j,k]].prod(1).mean())\n",
    "        m4_model[ii]+= (dx[:, [i,j,k,l]].prod(1).mean())\n",
    "m2_model/=ntries\n",
    "m3_model/=ntries\n",
    "m4_model/=ntries\n",
    "\n",
    "np.savetxt(f'{folder}_m2model_{d}_all.dat',m2_model)\n",
    "np.savetxt(f'{folder}_m3model_{d}_all.dat',m3_model)\n",
    "np.savetxt(f'{folder}_m4model_{d}_all.dat',m4_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12feee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(m2,m2_model, s=2)\n",
    "plt.scatter(m3,m3_model, s=2)\n",
    "plt.scatter(m4,m4_model, s=2)\n",
    "\n",
    "xmin, xmax = plt.gca().get_xlim()\n",
    "xx = np.linspace(xmin,xmax,100)\n",
    "plt.plot(xx,xx, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db42644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------- higher moments IN CLASS\n",
    "# if label!='all':\n",
    "#     folder = '../../../../scratch/network/csarra/allen_saved/binary/'\n",
    "#     ijkl = (np.loadtxt(f'{folder}_m4_{d}_{label}.dat')[:,1:]).astype(int)\n",
    "\n",
    "#     m2 = np.loadtxt(f'{folder}_m2_{d}_{label}.dat')[:,0]\n",
    "#     m3 = np.loadtxt(f'{folder}_m3_{d}_{label}.dat')[:,0]\n",
    "#     m4 = np.loadtxt(f'{folder}_m4_{d}_{label}.dat')[:,0]\n",
    "\n",
    "#     dx= np.array(x-f_model[:d])\n",
    "\n",
    "#     moms =[]\n",
    "#     for i,j,k,l in ijkl:\n",
    "#         moms.append(((dx[:,i]*dx[:,j]).mean(),(dx[:,i]*dx[:,j]*dx[:,k]).mean(),(dx[:,i]*dx[:,j]*dx[:,k]*dx[:,l]).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- SUM\n",
    "zsum = np.loadtxt(f'{folder_bin}_histosum_{d}_{label}.dat')\n",
    "zsums = np.loadtxt(f'{folder_bin}_histosums_{d}_{label}.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa8df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=[]\n",
    "for _ in trange(500):\n",
    "    x, energy_history = thermalize(x,J,h, NumSteps=1000 , crange =range)\n",
    "    s.append(x.numpy().sum(1))\n",
    "s=np.array(s).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36133d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo = np.histogram(np.array(x).sum(1), np.arange(-d,d,2)-1, density=True);\n",
    "histo = np.histogram(s, np.arange(-d,d,2)-1, density=True);\n",
    "np.savetxt(f'{folder_bin}_histosum_{d}_{label}_MODEL.dat',histo[0])\n",
    "\n",
    "\n",
    "plt.plot(histo[1][:-1], zsums/zsums.sum()/2, 'o--', label='data shuffled', color='blue')\n",
    "plt.plot(histo[1][:-1], zsum/zsum.sum()/2, 'o--', label='data', color='black')\n",
    "plt.plot(histo[1][:-1], histo[0],'o--', label='model', color='red')\n",
    "\n",
    "plt.title(f'class {label}')\n",
    "# plt.yscale('log')\n",
    "# plt.legend()\n",
    "plt.xlabel(r'$z = \\sum_i \\sigma_i$')\n",
    "plt.ylabel('P(z)')\n",
    "\n",
    "plt.xticks(fontsize=14);\n",
    "plt.yticks(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe60d6d",
   "metadata": {},
   "source": [
    "## independent case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987866ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d=500\n",
    "# label='all'\n",
    "# label=2\n",
    "\n",
    "f_data = np.loadtxt(f'{folder_bin}f_data_{d}_{label}.dat')\n",
    "q1 = np.log((1-f_data[:d])/(1+f_data[:d]))/2*d\n",
    "qind = np.hstack((q1, [0]*int(d*(d-1)/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d72c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------2. Find parameters\n",
    "h,J = get_hJ(qind,d)\n",
    "h = tf.convert_to_tensor(h,dtype=tf.float64)\n",
    "J= tf.convert_to_tensor(J,dtype=tf.float64)\n",
    "\n",
    "n_samples = 20000\n",
    "x = np.random.choice([-1,1], (n_samples,d))\n",
    "x = tf.convert_to_tensor(x,dtype=tf.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de12bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_thermalize = 50000\n",
    "x, energy_history = thermalize(x,J,h, NumSteps=n_thermalize , crange =trange)\n",
    "plt.plot(energy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, f_model = compute_f(x,J,h,StepsTherm=1000,NumSteps=500, crange=lambda NumSteps, dtype: trange(NumSteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b606c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{folder_bin}f_model_IND_{d}_{label}.dat',f_model.numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd1bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72452593",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = np.loadtxt(f'{folder}_m2_{d}_{label}.dat')[:,0]\n",
    "m3 = np.loadtxt(f'{folder}_m3_{d}_{label}.dat')[:,0]\n",
    "m4 = np.loadtxt(f'{folder}_m4_{d}_{label}.dat')[:,0]\n",
    "indices = np.loadtxt(f'{folder}_m4_{d}_{label}.dat')[:,1:].astype(int)\n",
    "\n",
    "m2_model=np.zeros(len(m2))\n",
    "m3_model=np.zeros(len(m2))\n",
    "m4_model=np.zeros(len(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntries=500\n",
    "for _ in trange(ntries):\n",
    "    x, energy_history = thermalize(x,J,h, NumSteps=1000 , crange =range)\n",
    "    dx = x.numpy()-x.numpy().mean(0)\n",
    "    for ii in range(len(indices)):\n",
    "        i,j,k,l = indices[ii]   \n",
    "        m2_model[ii]+= (dx[:, [i,j]].prod(1).mean())\n",
    "        m3_model[ii]+= (dx[:, [i,j,k]].prod(1).mean())\n",
    "        m4_model[ii]+= (dx[:, [i,j,k,l]].prod(1).mean())\n",
    "m2_model/=ntries\n",
    "m3_model/=ntries\n",
    "m4_model/=ntries\n",
    "\n",
    "np.savetxt(f'{folder}_m2IND_{d}_all.dat',m2_model)\n",
    "np.savetxt(f'{folder}_m3IND_{d}_all.dat',m3_model)\n",
    "np.savetxt(f'{folder}_m4IND_{d}_all.dat',m4_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e538c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{folder_bin}qIND_{d}_{label}.dat', np.array(qind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f5851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(m2,m2_model, s=2)\n",
    "plt.scatter(m3,m3_model, s=2)\n",
    "plt.scatter(m4,m4_model, s=2)\n",
    "\n",
    "xmin, xmax = plt.gca().get_xlim()\n",
    "xx = np.linspace(xmin,xmax,100)\n",
    "plt.plot(xx,xx, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e8afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3202254d",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 200\n",
    "label='all'\n",
    "\n",
    "q = np.loadtxt(f'{folder_bin}q_{d}_{label}.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477498c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zsel = np.loadtxt(f'{folder_bin}_datasel_{d}.dat')[:]\n",
    "lsel = np.loadtxt(f'{folder_bin}_datasel_label_{d}.dat')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fef5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima=[]\n",
    "for i in trange(10000,len(zsel)):\n",
    "    cell= zsel[i]\n",
    "    minima.append(get_minimum(cell,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5557bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima= np.array(minima)  \n",
    "tupled_lst = set(map(tuple, minima))\n",
    "lst = np.array(list(map(list, tupled_lst)))\n",
    "basin =[]\n",
    "for i in range(len(minima)):\n",
    "    basin.append(np.where((minima[i] == lst).prod(1)==1)[0][0])\n",
    "basin = np.array(basin)\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_of_basn = np.array([mode(lsel[basin==i]) for i in range(1+int(basin.max()))])\n",
    "lsel_pred = np.zeros(len(lsel))\n",
    "for i in range(len(lsel_pred)):\n",
    "    lsel_pred[i] = class_of_basn[basin[i]]\n",
    "## complessive accuracy\n",
    "accuracy = (lsel_pred == lsel).sum()/len(lsel)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = folder_bin = '../../../../scratch/network/csarra/allen_saved/binary/'\n",
    "np.savetxt(f'{folder}_datasel_labelPRED_{d}.dat',lsel_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39296551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ SAVE\n",
    "folder_saved = 'art_saved/'\n",
    "# acc_ising = []\n",
    "acc_ising = np.loadtxt(f'{folder_saved}acc_ising.dat')\n",
    "acc_ising = [i for i in acc_ising]\n",
    "\n",
    "acc_ising.append((d,accuracy))\n",
    "np.savetxt(f'{folder_saved}acc_ising.dat', np.array(acc_ising))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a29a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy per class\n",
    "acc_per_class = np.array([(lsel_pred[lsel==k] == lsel[lsel==k]).sum()/len(lsel[lsel==k]) for k in [1,2,9,28,29,30,31,33]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77328bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lst, aspect='auto', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a307aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lst.sum(1),200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab8fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_toclass = np.array([mode(lsel[basin==i]) for i in range(len(lst))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09767987",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lst_toclass, lst.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(lsel==k).sum() for k in [1,2,9,28,29,30,31,33]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lsel_pred[lsel==2], [1,2,9,28,29,30,31,33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----------- energy barrier\n",
    "# d = len(x0)\n",
    "\n",
    "# x = np.copy(x0)\n",
    "# actual_energy=[]\n",
    "# h,J = get_hJ(q,d)\n",
    "# actual_energy.append(get_H(x0[None,:],J,h)[0])\n",
    "\n",
    "# for _ in range(100000):  #steps allowed to find a minimum  \n",
    "#     xx = np.repeat(x[None,:],d,0) \n",
    "\n",
    "#     num_part,d = xx.shape\n",
    "#     indices_sel = range(num_part)\n",
    "#     Dh_h = tf.gather(h, indices_sel)\n",
    "#     Dh_J = tf.reduce_sum(tf.gather(J, indices_sel, batch_dims=0)*xx,1)\n",
    "#     DH = -2 * tf.gather(xx,indices_sel, batch_dims=1)*(Dh_h + 2*Dh_J)/d\n",
    "\n",
    "#     DH = np.array(DH)\n",
    "#     if DH.min()<0:\n",
    "#         isel = np.argmin(DH)\n",
    "#         x[isel]*=-1\n",
    "#         actual_energy.append(actual_energy[-1]+DH[isel])\n",
    "#     else:     \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting from the minima, compute their energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9480e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,J = get_hJ(q,d)\n",
    "energy_lst = get_H(lst,J,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lst_toclass, energy_lst, s=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(energy_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61150647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start from a certain minimum x0 with energy x0min\n",
    "\n",
    "lst_barriers =np.zeros(len(lst))\n",
    "ended_state=[]\n",
    "for imin in trange(0,len(lst),10):\n",
    "    x0 = lst[imin]\n",
    "    x0min = lst[imin]\n",
    "    d = len(x0)\n",
    "\n",
    "    x = np.copy(x0)\n",
    "    actual_energy=[]\n",
    "    h,J = get_hJ(q,d)\n",
    "    actual_energy.append(get_H(x0[None,:],J,h)[0])\n",
    "\n",
    "    for _ in range(5000):\n",
    "        # find the steepest way up\n",
    "        xx = np.repeat(x[None,:],d,0) \n",
    "        num_part,d = xx.shape\n",
    "        indices_sel = range(num_part)\n",
    "        Dh_h = tf.gather(h, indices_sel)\n",
    "        Dh_J = tf.reduce_sum(tf.gather(J, indices_sel, batch_dims=0)*xx,1)\n",
    "        DH = -2 * tf.gather(xx,indices_sel, batch_dims=1)*(Dh_h + 2*Dh_J)/d\n",
    "        DH = np.array(DH)\n",
    "\n",
    "        if DH.max()>0:\n",
    "            isel = np.argmax(DH)\n",
    "            x[isel]*=-1\n",
    "            actual_energy.append(actual_energy[-1]+DH[isel])\n",
    "\n",
    "            corr_basin = get_minimum(x,q)\n",
    "\n",
    "            if (corr_basin==x0).prod()==0:\n",
    "#                 print('stopped!')\n",
    "\n",
    "                ended = x\n",
    "                barrier =(actual_energy[-1]-actual_energy[0]).numpy()\n",
    "#                 print(ended, barrier)\n",
    "                lst_barriers[imin] = barrier\n",
    "                ended_state.append(corr_basin)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660dbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ac6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lst_barriers,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ended_state,aspect='auto', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "ended_state=np.array(ended_state)\n",
    "ended_state_tupled_lst = set(map(tuple, ended_state))\n",
    "ended_state_lst = np.array(list(map(list, ended_state_tupled_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ended_state_lst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f061ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ended_state.shape, lst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a90d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ended_state[:,None]==lst[None,:]).prod(-1).argmax(1), (ended_state[:,None]==lst[None,:]).prod(-1).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff65082",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_H(ended_state_lst,J,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----------- energy barrier\n",
    "# for _ in range(100000):  #steps allowed to find a minimum  \n",
    "#     xx = np.repeat(x[None,:],d,0) \n",
    "#     num_part,d = xx.shape\n",
    "#     indices_sel = range(num_part)\n",
    "#     Dh_h = tf.gather(h, indices_sel)\n",
    "#     Dh_J = tf.reduce_sum(tf.gather(J, indices_sel, batch_dims=0)*xx,1)\n",
    "#     DH = -2 * tf.gather(xx,indices_sel, batch_dims=1)*(Dh_h + 2*Dh_J)/d\n",
    "#     DH = np.array(DH)\n",
    "#     if DH.max()>0:\n",
    "#         isel = np.argmax(DH)\n",
    "#         x[isel]*=-1\n",
    "#         actual_energy.append(actual_energy[-1]+DH[isel])       \n",
    "#         xmin = get_minimum(x) \n",
    "#     else:     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{folder_saved}acc_ising.dat', np.array(acc_ising))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b004e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [per class accuracy]\n",
    "[(lsel_pred[lsel ==k] == lsel[lsel ==k]).sum()/len(lsel[lsel ==k]) for k in [1,2,9,28,29,30,31,33]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b049a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,J = get_hJ(q,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e92858",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_lst = np.array(get_H(lst,J,h))\n",
    "energy_lst_sorted = np.sort(energy_lst)\n",
    "\n",
    "lst_sorted = lst[np.argsort(energy_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_sorted =[]\n",
    "for i in range(len(minima)):\n",
    "    basin_sorted.append(np.where((minima[i] == lst_sorted).prod(1)==1)[0][0])\n",
    "basin_sorted = np.array(basin_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_sizes = np.array([(basin==i).sum() for i in range(len(lst))])\n",
    "basin_sorted_sizes = np.array([(basin_sorted==i).sum() for i in range(len(lst))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896dab04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(len(lst)), energy_lst_sorted, s=basin_sorted_sizes/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0575a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_basin = np.array(list(dict.fromkeys(basin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb580be",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_sorted_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b52f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_basin = np.array(list(dict.fromkeys(basin_sorted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b203ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0511ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lst_basin:\n",
    "    hhisto = plt.hist(lsel[basin==i],  range(34));\n",
    "    plt.title(f'basin {i}, largest: {hhisto[1][1:][np.argmax(hhisto[0])]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b979265",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lsel, range(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f35001",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = np.array(list(dict.fromkeys(lsel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f240b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in label_list:\n",
    "    hhisto = plt.hist(basin_sorted[lsel==i],  range(25));\n",
    "    plt.title(f'class {i}, largest: {hhisto[1][1:][np.argmax(hhisto[0])]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de20ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b977eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "for i in range(len(list_classes)):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(f_data_all[:d], f_data_i[i][:d], s=5)\n",
    "    plt.xlabel('m_all')\n",
    "    plt.ylabel('m_class')\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    xmin, xmax = plt.gca().get_xlim()\n",
    "    xx = np.linspace(xmin,xmax,100)\n",
    "    plt.plot(xx,xx, color='grey')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(f_data_all[d:], f_data_i[i][d:], s=5)\n",
    "    plt.xlabel('m2_all')\n",
    "    plt.ylabel('m2_class')\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    xmin, xmax = plt.gca().get_xlim()\n",
    "    xx = np.linspace(xmin,xmax,100)\n",
    "    plt.plot(xx,xx, color='grey')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ed952",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "for i in range(len(list_classes)):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(q_all[:d]/d, q_i[i][:d]/d, s=15)\n",
    "    plt.xlabel('h_all')\n",
    "    plt.ylabel('h_class')\n",
    "    xmin, xmax = plt.gca().get_xlim()\n",
    "    xx = np.linspace(xmin,xmax,100)\n",
    "    plt.plot(xx,xx, color='grey')    \n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(q_all[d:]/d, q_i[i][d:]/d, s=15)\n",
    "    plt.xlabel('J_all')\n",
    "    plt.ylabel('J_class')\n",
    "    xmin, xmax = plt.gca().get_xlim()\n",
    "    xx = np.linspace(xmin,xmax,100)\n",
    "    plt.plot(xx,xx, color='grey')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d612c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(len(list_classes)):\n",
    "    histo = np.histogram(q_i[i][:d]/d,density=True)\n",
    "    plt.plot(histo[1][1:], histo[0])\n",
    "    plt.xlabel('h')\n",
    "    plt.ylabel('P(h)')\n",
    "    \n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "for i in range(len(list_classes)):\n",
    "    histo = np.histogram(q_i[i][d:]/d,100,density=True)\n",
    "    plt.plot(histo[1][1:], histo[0])\n",
    "    plt.xlabel('J')\n",
    "    plt.ylabel('P(J)')\n",
    "plt.xlim(-0.2,0.2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "for i in range(len(list_classes)):\n",
    "    plt.subplot(1,2,1)\n",
    "    histo = np.histogram(f_data_i[i][:d], 10, density=True)\n",
    "    plt.plot(histo[1][1:], histo[0])\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    histo = np.histogram(f_data_i[i][d:], 100, density=True)\n",
    "    plt.plot(histo[1][1:], histo[0])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumSteps=1000\n",
    "StepsTherm=10\n",
    "d = len(x[0])\n",
    "energy_x_class =[]\n",
    "for i in range(N_CLASSES):\n",
    "    q = q_i[i]\n",
    "    h,J = get_hJ(q,d)\n",
    "    H1 = get_H(x,J,h)\n",
    "    energy_x_class.append(H1)\n",
    "energy_x_class = np.array(energy_x_class)\n",
    "\n",
    "h2,J2 = get_hJ(q_all,d)\n",
    "h2 = tf.convert_to_tensor(h2,dtype=tf.float64)\n",
    "J2= tf.convert_to_tensor(J2,dtype=tf.float64)\n",
    "H2 = get_H(x,J2,h2)\n",
    "\n",
    "num_part,d = x.shape\n",
    "num_par = int(d+ d*(d-1)/2)\n",
    "\n",
    "ratio = np.zeros(N_CLASSES)\n",
    "ratio_history=[]\n",
    "for n in trange(NumSteps):\n",
    "    for _ in tf.range(StepsTherm):\n",
    "        x,H2 = one_step_MC(x, h2,J2,H2)\n",
    "        \n",
    "    energy_x_class =[]\n",
    "    for i in range(N_CLASSES):\n",
    "        q = q_i[i]\n",
    "        h,J = get_hJ(q,d)\n",
    "        H1 = get_H(x,J,h)\n",
    "        energy_x_class.append(H1)\n",
    "    energy_x_class = np.array(energy_x_class) \n",
    "    \n",
    "\n",
    "    ratio_partial = tf.reduce_mean(tf.exp(-(energy_x_class-H2)),1)\n",
    "    ratio = (n*ratio + ratio_partial)/(n+1)  \n",
    "    ratio_history.append(np.array(ratio).mean())\n",
    "ratio = ratio.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628907a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.zeros(N_CLASSES)\n",
    "ratio_history=[]\n",
    "n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumSteps=10000\n",
    "for _ in trange(NumSteps):\n",
    "    for _ in tf.range(StepsTherm):\n",
    "        x,H2 = one_step_MC(x, h2,J2,H2)\n",
    "        \n",
    "    energy_x_class =[]\n",
    "    for i in range(N_CLASSES):\n",
    "        q = q_i[i]\n",
    "        h,J = get_hJ(q,d)\n",
    "        H1 = get_H(x,J,h)\n",
    "        energy_x_class.append(H1)\n",
    "    energy_x_class = np.array(energy_x_class) \n",
    "    \n",
    "\n",
    "    ratio_partial = tf.reduce_mean(tf.exp(-(energy_x_class-H2)),1)\n",
    "    ratio = (n*ratio + ratio_partial)/(n+1)  \n",
    "    ratio_history.append(np.array(ratio).mean())\n",
    "    n+=1\n",
    "ratio = ratio.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90564659",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ratio_history[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f60815",
   "metadata": {},
   "source": [
    "## ~ bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc582a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Pclass from labels\n",
    "pclass_ = np.loadtxt(f'{folder_bin}pclass.dat')\n",
    "if (pclass_[:,0].astype(int) == list_classes).prod() ==1:\n",
    "    pclass = pclass_[:,1]\n",
    "    print('pclass correctly loaded')\n",
    "else: \n",
    "    print('there is a problem')\n",
    "    print(pclass_[:,0].astype(int), list_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load x,y to test the classifier\n",
    "x = np.loadtxt(f'{folder_bin}_datasel_{d}.dat')[:5000]\n",
    "y = np.loadtxt(f'{folder_bin}_datasel_label_{d}.dat')[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find H(x|y)\n",
    "\n",
    "energy_x_class =[]\n",
    "\n",
    "for i in trange(N_CLASSES):\n",
    "    q = q_i[i]\n",
    "    h,J = get_hJ(q,d)\n",
    "    \n",
    "    H1 = get_H(x,J,h)\n",
    "    energy_x_class.append(H1)\n",
    "energy_x_class = np.array(energy_x_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55add5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find P(y|x) propto exp(-H_class)P_class/r_class\n",
    "prob_y_given_x_nn = np.exp(-energy_x_class)*pclass[:,None]/ratio[:,None]\n",
    "prob_y_given_x = prob_y_given_x_nn/prob_y_given_x_nn.sum(0)\n",
    "np.savetxt(f'{folder_bin}pyx_{d}.txt',prob_y_given_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35d681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55ae56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8f8c4bc",
   "metadata": {},
   "source": [
    "## load p(y|x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_given_x = np.loadtxt(f'{folder_bin}pyx_{d}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21220bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = 100\n",
    "plt.bar(np.arange(N_CLASSES), prob_y_given_x[:,cell])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prob_y_given_x.flatten(),100);\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c0f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_temp = np.argmax(prob_y_given_x,0)\n",
    "y_pred = np.copy(y_pred_temp)\n",
    "for i in range(N_CLASSES):\n",
    "    y_pred[y_pred_temp==i]=list_classes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02401ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=(y_pred == y).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_saved = 'art_saved/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_isingMIx = np.loadtxt(f'{folder_saved}acc_isingMix.dat')\n",
    "# ###-----------------------------------\n",
    "# # acc_isingMIx =[] #-------- only if there isn't acc_n\n",
    "# acc_isingMIx = [i for i in acc_isingMIx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d296ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_isingMIx.append((d,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dcb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_isingMIx.append((d, acc))    \n",
    "# np.savetxt(f'{folder_saved}acc_isingMix.dat', np.array(acc_isingMIx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2eeca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, N_CLASSES*10,alpha=0.5);\n",
    "plt.hist(y_pred, N_CLASSES*10,alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8920925",
   "metadata": {},
   "source": [
    "# LOAD CLASSIFIER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b09e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Pclass from labels\n",
    "pclass_ = np.loadtxt(f'{folder_bin}pclass.dat')\n",
    "pclass = pclass_[:,1]\n",
    "list_classes =np.array([1,30,31,33,9,29,2,28])\n",
    "H_y = -(pclass*np.log(pclass)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__________________________________________________________________________________\n",
    "# ---------------------- Conditional independent model\n",
    "#__________________________________________________________________________________\n",
    "\n",
    "cond_ind_classifier =[]\n",
    "cond_ind_mi =[]\n",
    "for d in [10,15,50,100,200,300,400,500]:\n",
    "    x = np.loadtxt(f'{folder_bin}_datasel_{d}.dat')\n",
    "    y = np.loadtxt(f'{folder_bin}_datasel_label_{d}.dat')\n",
    "    list_classes =np.array([1,30,31,33,9,29,2,28])\n",
    "    label='all'\n",
    "    prob_y_given_x_nn=[]\n",
    "    ii=0\n",
    "    for label in list_classes:\n",
    "\n",
    "        f_data = np.loadtxt(f'{folder_bin}f_data_{d}_{label}.dat')\n",
    "        mu = f_data[:d]\n",
    "        a_ind_real = 1/2*np.log((1-mu+1e-8)/(1+mu))\n",
    "        prob_x_given_y = (np.exp(-a_ind_real*x)/(np.exp(a_ind_real)+np.exp(-a_ind_real))).prod(-1)\n",
    "\n",
    "        prob_y_given_x_nn.append(prob_x_given_y*pclass[ii])\n",
    "\n",
    "        ii+=1\n",
    "    prob_y_given_x_nn = np.vstack((prob_y_given_x_nn))\n",
    "\n",
    "    prob_y_given_x = prob_y_given_x_nn/prob_y_given_x_nn.sum(0)\n",
    "    y_pred_temp = np.argmax(prob_y_given_x, 0)\n",
    "\n",
    "    y_pred = np.copy(y_pred_temp)\n",
    "    for i in range(N_CLASSES):\n",
    "        y_pred[y_pred_temp==i]=list_classes[i]\n",
    "    cond_ind_classifier.append((d,(y_pred == y).sum()/len(y)))\n",
    "    \n",
    "    \n",
    "    H_y_given_x = (-(prob_y_given_x*np.log(prob_y_given_x)).sum(0)).mean()\n",
    "    mutual_info = H_y - H_y_given_x\n",
    "    cond_ind_mi.append((d, mutual_info))\n",
    "cond_ind_mi = np.array(cond_ind_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361824c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accuracy=[]\n",
    "for d in [10,50,100]:\n",
    "    prob_y_given_x = np.loadtxt(f'{folder_bin}pyx_{d}.txt')\n",
    "    y = np.loadtxt(f'{folder_bin}_datasel_label_{d}.dat')    \n",
    "    plt.hist(prob_y_given_x.flatten(),100, label=d);\n",
    "    \n",
    "    y_pred_temp = np.argmax(prob_y_given_x,0)\n",
    "    y_pred = np.copy(y_pred_temp)\n",
    "    for i in range(N_CLASSES):\n",
    "        y_pred[y_pred_temp==i]=list_classes[i]\n",
    "    class_accuracy.append((d,(y_pred == y).sum()/len(y)))\n",
    "    \n",
    "    \n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1580d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.axhline(H_y, color='grey', ls='--')\n",
    "plt.ylabel('I(x,class)')\n",
    "plt.xlabel('n genes')\n",
    "\n",
    "\n",
    "dmi =[]\n",
    "for d in [10,15,50,100]:\n",
    "    prob_y_given_x = np.loadtxt(f'{folder_bin}pyx_{d}.txt')\n",
    "    # we want this to be as small as possible! (max value is H_y)\n",
    "    H_y_given_x = (-(prob_y_given_x*np.log(prob_y_given_x)).sum(0)).mean()\n",
    "    mutual_info = H_y - H_y_given_x\n",
    "    plt.scatter(d, mutual_info, color='black')\n",
    "    dmi.append((d,mutual_info))\n",
    "dmi = np.array(dmi)\n",
    "    \n",
    "# plt.scatter(cond_ind_mi[:,0], cond_ind_mi[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_accuracy = np.array(class_accuracy)\n",
    "# plt.scatter(class_accuracy[:,0], class_accuracy[:,1])\n",
    "\n",
    "#------------------------ NN classifier\n",
    "saved_classifier = np.loadtxt(f'{folder_bin}Classifier.txt')\n",
    "plt.scatter(saved_classifier[:,0][-1], saved_classifier[:,1][-1], color='red')\n",
    "nn = np.array(list(dict.fromkeys(saved_classifier[:,0])))\n",
    "class_mean = np.array([saved_classifier[:,1][saved_classifier[:,0]==nn[i]].mean() for i in range(len(nn))])\n",
    "class_std  = np.array([saved_classifier[:,1][saved_classifier[:,0]==nn[i]].std() for i in range(len(nn))])\n",
    "class_num = np.array([(saved_classifier[:,0]==nn[i]).sum() for i in range(len(nn))])\n",
    "plt.errorbar(nn, class_mean, class_std/np.sqrt(class_num-1), ls='--', color='red')\n",
    "plt.scatter(nn, class_mean, color='red', label='classifier')\n",
    "\n",
    "# ----------------------- ISING MODEL\n",
    "class_accuracy = np.array(class_accuracy)\n",
    "plt.scatter(class_accuracy[:,0], class_accuracy[:,1], color='black', label='Ising mixture')\n",
    "\n",
    "# #------------------------- independent\n",
    "# cond_ind_classifier = np.array(cond_ind_classifier)\n",
    "# plt.scatter(cond_ind_classifier[:,0], cond_ind_classifier[:,1], label =' cond ind')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.xlabel('number of genes')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df670d53",
   "metadata": {},
   "source": [
    "# Heat capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "\n",
    "for label in [2]:\n",
    "    q = np.loadtxt(f'{folder_bin}q_{d}_{label}.dat')\n",
    "    h,J=get_hJ(q,d)\n",
    "    \n",
    "    # thermalize particles at T=1\n",
    "    n_samples = 1000\n",
    "    x = np.random.choice([-1,1], (n_samples,d))\n",
    "    x = tf.convert_to_tensor(x,dtype=tf.float64) \n",
    "    \n",
    "    for _ in range(2):\n",
    "        n_thermalize = 10000\n",
    "        x, energy_history = thermalize(x,J,h, NumSteps=n_thermalize , crange =trange)\n",
    "        plt.plot(energy_history)\n",
    "        plt.show()\n",
    "    x1=np.copy(x)\n",
    "    \n",
    "    \n",
    "    heat_capacity =[]\n",
    "    # ---------------------\n",
    "    e_mean = (np.array(get_H(x,J,h))).mean()\n",
    "    e_var = ((np.array(get_H(x,J,h)) - e_mean)**2).mean()\n",
    "    n_thermalize = 100\n",
    "    x=np.copy(x1)\n",
    "    for T in np.linspace(1,3,20):\n",
    "        e_var =0\n",
    "        x, energy_history = thermalize(x,J/T,h/T, NumSteps=n_thermalize , crange =trange)\n",
    "        for k in range(1,3):\n",
    "            x, energy_history = thermalize(x,J/T,h/T, NumSteps=50 , crange =range)\n",
    "            e_mean = (np.array(get_H(x,J,h))).mean()\n",
    "            e_var1 = ((np.array(get_H(x,J,h)) - e_mean)**2).mean()\n",
    "            e_var = (e_var*(k-1) + e_var1)/k\n",
    "        heat_capacity.append((T,e_var/T**2))\n",
    "    x=np.copy(x1)\n",
    "    n_thermalize = 5000\n",
    "    for T in np.linspace(0.95,0.1,10):\n",
    "        e_var =0\n",
    "        x, energy_history = thermalize(x,J/T,h/T, NumSteps=n_thermalize , crange =trange)\n",
    "        for k in range(1,3):\n",
    "            x, energy_history = thermalize(x,J/T,h/T, NumSteps=200 , crange =range)\n",
    "            e_mean = (np.array(get_H(x,J,h))).mean()\n",
    "            e_var1 = ((np.array(get_H(x,J,h)) - e_mean)**2).mean()\n",
    "            e_var = (e_var*(k-1) + e_var1)/k\n",
    "        heat_capacity.append((T,e_var/T**2)) \n",
    "        \n",
    "    hc = np.array(heat_capacity)[:-1]\n",
    "    plt.scatter(hc[:,0], hc[:,1])\n",
    "    plt.show()\n",
    "    np.savetxt(f'hc_{d}_{label}.dat', hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "d= 10\n",
    "plt.subplot(1,2,1)    \n",
    "for label in [2,9,28,29,30,31,33]:\n",
    "    hc = np.loadtxt(f'hc_{d}_{label}.dat')\n",
    "    plt.plot(hc[:,0][np.argsort(hc[:,0])], hc[:,1][np.argsort(hc[:,0])]/d)\n",
    "plt.gca().set_prop_cycle(None)    \n",
    "plt.xlabel('T')\n",
    "plt.ylabel('C(T)/N')\n",
    "plt.axvline(1,ls='--', color='grey')\n",
    "plt.ylim(0,1.5)\n",
    "plt.title('N=10')\n",
    "\n",
    "\n",
    "d= 100\n",
    "plt.subplot(1,2,2)    \n",
    "for label in [2,9,28,29,30,31,33]:\n",
    "    hc = np.loadtxt(f'hc_{d}_{label}.dat')\n",
    "    plt.plot(hc[:,0][np.argsort(hc[:,0])], hc[:,1][np.argsort(hc[:,0])]/d)\n",
    "plt.gca().set_prop_cycle(None)    \n",
    "plt.xlabel('T')\n",
    "plt.ylabel('C(T)/N')\n",
    "plt.axvline(1,ls='--', color='grey')\n",
    "plt.ylim(0,1.5)\n",
    "plt.title('N=100')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ebfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08337468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hc_all = np.copy(hc)\n",
    "# hc_33 = np.copy(hc)\n",
    "hc_9= np.copy(hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hc in [hc_9]:\n",
    "    plt.plot(hc[:,0][np.argsort(hc[:,0])], hc[:,1][np.argsort(hc[:,0])])\n",
    "    \n",
    "# hc   = hc_all\n",
    "# plt.plot(hc[:,0][np.argsort(hc[:,0])], hc[:,1][np.argsort(hc[:,0])], color='black', lw=2)\n",
    "\n",
    "plt.axvline(1,ls='--', color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f122fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(f'{folder_bin}heat_capacity_{d}.txt',hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12498071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat_capacity =[]\n",
    "# for T in tqdm(np.hstack((np.linspace(0.1,1,10), np.linspace(1.1,3,10)))):\n",
    "#     prob = np.exp(-a_ind_real/T)/2/np.cosh(a_ind_real/T)  \n",
    "#     en =[]\n",
    "#     for _ in range(100):\n",
    "#         x = np.array([np.random.choice([1,-1],p=(prob[i], 1-prob[i]),  size=500) for i in range(len(prob))]).T\n",
    "#         en.append(np.array(get_H(x,J,h)))\n",
    "#     en=np.array(en)\n",
    "#     e_var = np.var(en)\n",
    "#     heat_capacity.append((T, e_var/T**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcfba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=10\n",
    "\n",
    "all_points = get_p(d)\n",
    "mixed = ((all_points[:,None,:]*all_points[:,:,None])[:,np.triu_indices(d, k=1)[0],np.triu_indices(d, k=1)[1]])\n",
    "v_points = np.hstack((all_points,mixed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38986c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [1,2,9,28,29,30,31,33]:\n",
    "    q = np.loadtxt(f'{folder_bin}q_{d}_{label}.dat')\n",
    "    h,J=get_hJ(q,d)\n",
    "    hc =[]\n",
    "    for T in np.linspace(0.1,5,100):\n",
    "        h =np.array(tf.reduce_sum(v_points*q,1)/d)\n",
    "        p = np.exp(-h/T); p/=p.sum()\n",
    "        mean_energy = (h*p).sum() \n",
    "    #     var = ((h -mean_energy)**2*p).sum() \n",
    "        var = (h**2*p).sum() - (h*p).sum()**2 \n",
    "        hc.append((T,var/T**2))\n",
    "    hc = np.array(hc)\n",
    "    np.savetxt(f'hc_{d}_{label}.dat', hc)\n",
    "    plt.plot(hc[:,0], hc[:,1])\n",
    "plt.xlabel('T')\n",
    "plt.ylabel('C(T)')\n",
    "\n",
    "label='all'\n",
    "q = np.loadtxt(f'{folder_bin}q_{d}_{label}.dat')\n",
    "h,J=get_hJ(q,d)\n",
    "hc =[]\n",
    "for T in np.linspace(0.1,5,100):\n",
    "    h =np.array(tf.reduce_sum(v_points*q,1)/d)\n",
    "    p = np.exp(-h/T); p/=p.sum()\n",
    "    mean_energy = (h*p).sum() \n",
    "#     var = ((h -mean_energy)**2*p).sum() \n",
    "    var = (h**2*p).sum() - (h*p).sum()**2 \n",
    "    hc.append((T,var/T**2))\n",
    "hc = np.array(hc)\n",
    "plt.plot(hc[:,0], hc[:,1],color='black' ,lw=2)\n",
    "plt.xlabel('T')\n",
    "plt.ylabel('C(T)')\n",
    "\n",
    "plt.axvline(1,ls='--', color='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc6fba",
   "metadata": {},
   "source": [
    "# Conditional independent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec11492",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 200\n",
    "label='all'\n",
    "f_data = np.loadtxt(f'{folder_bin}f_data_{d}_{label}.dat')\n",
    "mu = f_data[:d]\n",
    "a_ind_real = np.log((1-mu+1e-10)/(1+mu))/2\n",
    "q = np.hstack((a_ind_real*d, [0]*int(d*(d-1)/2)))\n",
    "h,J=get_hJ(q,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a07209",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_capacity =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41286b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for T in tqdm(np.hstack((np.linspace(0.1,1,10), np.linspace(1.1,3,10)))):\n",
    "    prob = np.exp(-a_ind_real/T)/2/np.cosh(a_ind_real/T)  \n",
    "    en =[]\n",
    "    for _ in range(100):\n",
    "        x = np.array([np.random.choice([1,-1],p=(prob[i], 1-prob[i]),  size=500) for i in range(len(prob))]).T\n",
    "        en.append(np.array(get_H(x,J,h)))\n",
    "    en=np.array(en)\n",
    "    e_var = np.var(en)\n",
    "    heat_capacity.append((T, e_var/T**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = np.array(heat_capacity)\n",
    "plt.scatter(hc[:,0],hc[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146baa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'{folder_bin}heat_capacity_IND_{d}.txt',hc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7b2b3",
   "metadata": {},
   "source": [
    "# plot hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [50,100,200]:\n",
    "    hc = np.loadtxt(f'{folder_bin}heat_capacity_{d}.txt')  \n",
    "    plt.scatter(hc[:,0], hc[:,1]/d, label= d)\n",
    "    plt.plot(np.sort(hc[:,0]), hc[:,1][np.argsort(hc[:,0])]/d, '--')\n",
    "    \n",
    "    \n",
    "plt.axvline(1, ls='--', color='grey')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.xlabel('T')\n",
    "plt.ylabel('C(T)/N')\n",
    "plt.title('Ising model')\n",
    "\n",
    "plt.xticks(fontsize=14);\n",
    "plt.yticks(fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [50,100,200]:\n",
    "    hc = np.loadtxt(f'{folder_bin}heat_capacity_IND_{d}.txt')  \n",
    "    plt.scatter(hc[:,0], hc[:,1]/d, label= d)\n",
    "    plt.plot(np.sort(hc[:,0]), hc[:,1][np.argsort(hc[:,0])]/d, '--')\n",
    "plt.axvline(1, ls='--', color='grey')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('T')\n",
    "plt.ylabel('C(T)/N')\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,1)\n",
    "plt.title('Independent model')\n",
    "\n",
    "plt.xticks(fontsize=14);\n",
    "plt.yticks(fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "for d in [50,100,200]:\n",
    "    hc = np.loadtxt(f'{folder_bin}heat_capacity_{d}.txt')  \n",
    "    plt.scatter(hc[:,0], hc[:,1]/d, label= d)\n",
    "    plt.plot(np.sort(hc[:,0]), hc[:,1][np.argsort(hc[:,0])]/d, '--')\n",
    "    \n",
    "    \n",
    "plt.axvline(1, ls='--', color='grey')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.xlabel('T')\n",
    "plt.ylabel('C(T)/N')\n",
    "plt.title('Ising model')\n",
    "\n",
    "plt.xticks(fontsize=14);\n",
    "plt.yticks(fontsize=14);\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for d in [50,100,200]:\n",
    "    hc = np.loadtxt(f'{folder_bin}heat_capacity_IND_{d}.txt')  \n",
    "    plt.scatter(hc[:,0], hc[:,1]/d, label= d)\n",
    "    plt.plot(np.sort(hc[:,0]), hc[:,1][np.argsort(hc[:,0])]/d, '--')\n",
    "plt.axvline(1, ls='--', color='grey')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('T')\n",
    "plt.ylabel('C(T)/N')\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,1)\n",
    "plt.title('Independent model')\n",
    "\n",
    "plt.xticks(fontsize=14);\n",
    "plt.yticks(fontsize=14);\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37973b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zsel = np.loadtxt(f'{folder}_datasel_{d}.dat')[:100]\n",
    "lsel = np.loadtxt(f'{folder}_datasel_label_{d}.dat')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.loadtxt(f'{folder_bin}q_{d}_{label}.dat')\n",
    "q[:d]=np.zeros(len(q[:d]))\n",
    "\n",
    "minima=[]\n",
    "for i in trange(len(zsel)):\n",
    "    cell= zsel[i]\n",
    "    minima.append(get_minimum(cell,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3612d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima= np.array(minima)  \n",
    "tupled_lst = set(map(tuple, minima))\n",
    "lst = np.array(list(map(list, tupled_lst)))\n",
    "basin =[]\n",
    "for i in range(len(minima)):\n",
    "    basin.append(np.where((minima[i] == lst).prod(1)==1)[0][0])\n",
    "basin = np.array(basin)\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1add889",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d353c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_of_basn = np.array([mode(lsel[basin==i]) for i in range(1+int(basin.max()))])\n",
    "lsel_pred = np.zeros(len(lsel))\n",
    "for i in range(len(lsel_pred)):\n",
    "    lsel_pred[i] = class_of_basn[basin[i]]\n",
    "    \n",
    "## complessive accuracy\n",
    "accuracy = (lsel_pred == lsel).sum()/len(lsel)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zsel = np.loadtxt(f'{folder}_datasel_{d}.dat')[:1000]\n",
    "lsel = np.loadtxt(f'{folder}_datasel_label_{d}.dat')[:1000]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(zsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc38746",
   "metadata": {},
   "outputs": [],
   "source": [
    "zsel_pca = pca.transform(zsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a87f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b435778",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_classes:\n",
    "    plt.scatter(zsel_pca[lsel==i][:,0], zsel_pca[lsel==i][:,1], s=5, label=i)\n",
    "plt.legend(bbox_to_anchor=(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cenv [~/.conda/envs/cenv/]",
   "language": "python",
   "name": "conda_cenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
